{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('대구광역시', '남구'), ('대구광역시', '달서구'), ('대구광역시', '달성군'), ('대구광역시', '동구'), ('대구광역시', '북구')]\n"
     ]
    }
   ],
   "source": [
    "# print(text.split('\\n'))\n",
    "\n",
    "text = ['대구광역시 남구', '대구광역시 달서구', '대구광역시 달성군', '대구광역시 동구', '대구광역시 북구']\n",
    "text2 = ['대구광역시 서구', '대구광역시 수성구', '대구광역시 중구', '대구광역시 직속']\n",
    "        \n",
    "\n",
    "texts=[]\n",
    "for txt in text:\n",
    "    a = []\n",
    "    a.append(txt.split()[0])\n",
    "    a.append(' '.join(txt.split()[1:]))\n",
    "\n",
    "    texts.append(tuple(a))\n",
    "\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_23524\\1340717944.py:8: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(r'C:\\Users\\USER\\Desktop\\chromedriver\\chromedriver.exe')\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_23524\\1340717944.py:23: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(r'C:\\Users\\USER\\Desktop\\chromedriver\\chromedriver.exe')\n",
      "100%|██████████| 5/5 [3:57:41<00:00, 2852.39s/it]  \n"
     ]
    }
   ],
   "source": [
    "# 페이지 수 뽑기\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import time\n",
    "\n",
    "driver = webdriver.Chrome(r'C:\\Users\\USER\\Desktop\\chromedriver\\chromedriver.exe')\n",
    "driver.get('https://www.seniorro.or.kr:4431/seniorro/main/main.do')\n",
    "time.sleep(3)\n",
    "\n",
    "a=[]  # 지역 및 시군구 담을 리스트\n",
    "b=[]  # 기업명 담을 리스트\n",
    "c=[]  # 접수예정, 마감 담을 리스트\n",
    "d=[]  # 주소 담을 리스트\n",
    "e=[]  # 연락처 담을 리스트\n",
    "f=[]  # 구인사항 담을 리스트\n",
    "g=[]  # 접수마감일자 담을 리스트\n",
    "\n",
    "\n",
    "page_num = [0]*len(texts)\n",
    "for idx in tqdm(range(len(texts))):\n",
    "    driver = webdriver.Chrome(r'C:\\Users\\USER\\Desktop\\chromedriver\\chromedriver.exe')\n",
    "    driver.get('https://www.seniorro.or.kr:4431/seniorro/main/main.do')\n",
    "    time.sleep(3)\n",
    "    \n",
    "    driver.execute_script(f\"jobSearchAct02{texts[idx]}\")\n",
    "    time.sleep(3)\n",
    "    html=driver.page_source\n",
    "    soup=BeautifulSoup(html, 'html.parser')\n",
    "    div = soup.find('div',{'id':'paging02'})\n",
    "\n",
    "    try:\n",
    "        page_num[idx] = int(re.sub(r'[^0-9]', '', div.find_all('a')[-1]['href']))\n",
    " \n",
    "    except:\n",
    "        page_num[idx] = 0\n",
    "\n",
    "    for nums in page_num:\n",
    "        for num in range(1, nums+1):\n",
    "\n",
    "            time.sleep(3)\n",
    "            driver.execute_script(f\"javascript:jobList({str(num)},'')\")\n",
    "            # 해당 페이지 주소들 뽑기\n",
    "            ul = soup.find('ul',{'id':'rsList02'})\n",
    "\n",
    "            for i in ul.find_all('a'):\n",
    "                url = i['href']\n",
    "\n",
    "                # 원하는 자료 추출\n",
    "                driver.execute_script(url)\n",
    "                time.sleep(5)\n",
    "\n",
    "                html=driver.page_source\n",
    "                soup=BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "                ul = soup.find('div',{'id':'detailDiv'})\n",
    "                \n",
    "                try:    \n",
    "                    a.append(' '.join(texts[idx]))  # 지역 및 시군구\n",
    "                    b.append(ul.find('span',{'id':'dJobAnnounNm'}).text)  # 기업명\n",
    "                    c.append(ul.find('span',{'id':'dDeadLine'}).text)  # 접수예정, 마감\n",
    "                    d.append(ul.find('strong',{'id':'dAddr'}).text)  # 주소\n",
    "                    e.append(ul.find('strong',{'id':'dTelNo'}).text)  # 연락처\n",
    "                    f.append(ul.find('dd',{'id':'dDetCnts'}).text)   # 구인사항\n",
    "                    g.append(ul.find('dd',{'id':'dToAcptDd'}).text)  # 접수마감일자\n",
    "                    \n",
    "                except:\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'a':a, 'b':b, 'c':c, 'd':d, 'e':e, 'f':f, 'g':g})\n",
    "df.to_csv('대구1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('대구광역시', '서구'), ('대구광역시', '수성구'), ('대구광역시', '중구'), ('대구광역시', '직속')]\n"
     ]
    }
   ],
   "source": [
    "# print(text.split('\\n'))\n",
    "\n",
    "text = ['대구광역시 서구', '대구광역시 수성구', '대구광역시 중구', '대구광역시 직속']\n",
    "        \n",
    "\n",
    "texts=[]\n",
    "for txt in text:\n",
    "    a = []\n",
    "    a.append(txt.split()[0])\n",
    "    a.append(' '.join(txt.split()[1:]))\n",
    "\n",
    "    texts.append(tuple(a))\n",
    "\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_23524\\2393121606.py:19: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(r'C:\\Users\\USER\\Desktop\\chromedriver\\chromedriver.exe')\n",
      "100%|██████████| 4/4 [54:19<00:00, 814.76s/it] \n"
     ]
    }
   ],
   "source": [
    "# 페이지 수 뽑기\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import time\n",
    "\n",
    "a=[]  # 지역 및 시군구 담을 리스트\n",
    "b=[]  # 기업명 담을 리스트\n",
    "c=[]  # 접수예정, 마감 담을 리스트\n",
    "d=[]  # 주소 담을 리스트\n",
    "e=[]  # 연락처 담을 리스트\n",
    "f=[]  # 구인사항 담을 리스트\n",
    "g=[]  # 접수마감일자 담을 리스트\n",
    "\n",
    "\n",
    "page_num = [0]*len(texts)\n",
    "for idx in tqdm(range(len(texts))):\n",
    "    driver = webdriver.Chrome(r'C:\\Users\\USER\\Desktop\\chromedriver\\chromedriver.exe')\n",
    "    driver.get('https://www.seniorro.or.kr:4431/seniorro/main/main.do')\n",
    "    time.sleep(2)\n",
    "    \n",
    "    driver.execute_script(f\"jobSearchAct02{texts[idx]}\")\n",
    "    time.sleep(2)\n",
    "    html=driver.page_source\n",
    "    soup=BeautifulSoup(html, 'html.parser')\n",
    "    div = soup.find('div',{'id':'paging02'})\n",
    "\n",
    "    try:\n",
    "        page_num[idx] = int(re.sub(r'[^0-9]', '', div.find_all('a')[-1]['href']))\n",
    " \n",
    "    except:\n",
    "        page_num[idx] = 0\n",
    "\n",
    "    for nums in page_num:\n",
    "        for num in range(1, nums+1):\n",
    "\n",
    "            time.sleep(2)\n",
    "            driver.execute_script(f\"javascript:jobList({str(num)},'')\")\n",
    "            # 해당 페이지 주소들 뽑기\n",
    "            ul = soup.find('ul',{'id':'rsList02'})\n",
    "\n",
    "            for i in ul.find_all('a'):\n",
    "                url = i['href']\n",
    "\n",
    "                # 원하는 자료 추출\n",
    "                driver.execute_script(url)\n",
    "                time.sleep(2)\n",
    "\n",
    "                html=driver.page_source\n",
    "                soup=BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "                ul = soup.find('div',{'id':'detailDiv'})\n",
    "                \n",
    "                try:    \n",
    "                    a.append(' '.join(texts[idx]))  # 지역 및 시군구\n",
    "                    b.append(ul.find('span',{'id':'dJobAnnounNm'}).text)  # 기업명\n",
    "                    c.append(ul.find('span',{'id':'dDeadLine'}).text)  # 접수예정, 마감\n",
    "                    d.append(ul.find('strong',{'id':'dAddr'}).text)  # 주소\n",
    "                    e.append(ul.find('strong',{'id':'dTelNo'}).text)  # 연락처\n",
    "                    f.append(ul.find('dd',{'id':'dDetCnts'}).text)   # 구인사항\n",
    "                    g.append(ul.find('dd',{'id':'dToAcptDd'}).text)  # 접수마감일자\n",
    "                    \n",
    "                except:\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'a':a, 'b':b, 'c':c, 'd':d, 'e':e, 'f':f, 'g':g})\n",
    "df.to_csv('대구2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('울산광역시', '남구'), ('울산광역시', '동구'), ('울산광역시', '북구'), ('울산광역시', '울주군'), ('울산광역시', '중구'), ('울산광역시', '직속')]\n"
     ]
    }
   ],
   "source": [
    "# print(text.split('\\n'))\n",
    "\n",
    "text = ['울산광역시 남구', '울산광역시 동구', '울산광역시 북구', '울산광역시 울주군', '울산광역시 중구', '울산광역시 직속']\n",
    "        \n",
    "\n",
    "texts=[]\n",
    "for txt in text:\n",
    "    a = []\n",
    "    a.append(txt.split()[0])\n",
    "    a.append(' '.join(txt.split()[1:]))\n",
    "\n",
    "    texts.append(tuple(a))\n",
    "\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_23524\\2393121606.py:19: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(r'C:\\Users\\USER\\Desktop\\chromedriver\\chromedriver.exe')\n",
      "100%|██████████| 6/6 [56:32<00:00, 565.44s/it]   \n"
     ]
    }
   ],
   "source": [
    "# 페이지 수 뽑기\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import time\n",
    "\n",
    "a=[]  # 지역 및 시군구 담을 리스트\n",
    "b=[]  # 기업명 담을 리스트\n",
    "c=[]  # 접수예정, 마감 담을 리스트\n",
    "d=[]  # 주소 담을 리스트\n",
    "e=[]  # 연락처 담을 리스트\n",
    "f=[]  # 구인사항 담을 리스트\n",
    "g=[]  # 접수마감일자 담을 리스트\n",
    "\n",
    "\n",
    "page_num = [0]*len(texts)\n",
    "for idx in tqdm(range(len(texts))):\n",
    "    driver = webdriver.Chrome(r'C:\\Users\\USER\\Desktop\\chromedriver\\chromedriver.exe')\n",
    "    driver.get('https://www.seniorro.or.kr:4431/seniorro/main/main.do')\n",
    "    time.sleep(2)\n",
    "    \n",
    "    driver.execute_script(f\"jobSearchAct02{texts[idx]}\")\n",
    "    time.sleep(2)\n",
    "    html=driver.page_source\n",
    "    soup=BeautifulSoup(html, 'html.parser')\n",
    "    div = soup.find('div',{'id':'paging02'})\n",
    "\n",
    "    try:\n",
    "        page_num[idx] = int(re.sub(r'[^0-9]', '', div.find_all('a')[-1]['href']))\n",
    " \n",
    "    except:\n",
    "        page_num[idx] = 0\n",
    "\n",
    "    for nums in page_num:\n",
    "        for num in range(1, nums+1):\n",
    "\n",
    "            time.sleep(2)\n",
    "            driver.execute_script(f\"javascript:jobList({str(num)},'')\")\n",
    "            # 해당 페이지 주소들 뽑기\n",
    "            ul = soup.find('ul',{'id':'rsList02'})\n",
    "\n",
    "            for i in ul.find_all('a'):\n",
    "                url = i['href']\n",
    "\n",
    "                # 원하는 자료 추출\n",
    "                driver.execute_script(url)\n",
    "                time.sleep(2)\n",
    "\n",
    "                html=driver.page_source\n",
    "                soup=BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "                ul = soup.find('div',{'id':'detailDiv'})\n",
    "                \n",
    "                try:    \n",
    "                    a.append(' '.join(texts[idx]))  # 지역 및 시군구\n",
    "                    b.append(ul.find('span',{'id':'dJobAnnounNm'}).text)  # 기업명\n",
    "                    c.append(ul.find('span',{'id':'dDeadLine'}).text)  # 접수예정, 마감\n",
    "                    d.append(ul.find('strong',{'id':'dAddr'}).text)  # 주소\n",
    "                    e.append(ul.find('strong',{'id':'dTelNo'}).text)  # 연락처\n",
    "                    f.append(ul.find('dd',{'id':'dDetCnts'}).text)   # 구인사항\n",
    "                    g.append(ul.find('dd',{'id':'dToAcptDd'}).text)  # 접수마감일자\n",
    "                    \n",
    "                except:\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'a':a, 'b':b, 'c':c, 'd':d, 'e':e, 'f':f, 'g':g})\n",
    "df.to_csv('울산1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('광주광역시', '광산구'), ('광주광역시', '남구'), ('광주광역시', '동구'), ('광주광역시', '북구'), ('광주광역시', '서구'), ('광주광역시', '직속')]\n"
     ]
    }
   ],
   "source": [
    "# print(text.split('\\n'))\n",
    "\n",
    "text = ['광주광역시 광산구', '광주광역시 남구', '광주광역시 동구', '광주광역시 북구', '광주광역시 서구', '광주광역시 직속']\n",
    "        \n",
    "\n",
    "texts=[]\n",
    "for txt in text:\n",
    "    a = []\n",
    "    a.append(txt.split()[0])\n",
    "    a.append(' '.join(txt.split()[1:]))\n",
    "\n",
    "    texts.append(tuple(a))\n",
    "\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_23524\\2393121606.py:19: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(r'C:\\Users\\USER\\Desktop\\chromedriver\\chromedriver.exe')\n",
      "100%|██████████| 6/6 [1:10:06<00:00, 701.10s/it] \n"
     ]
    }
   ],
   "source": [
    "# 페이지 수 뽑기\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import time\n",
    "\n",
    "a=[]  # 지역 및 시군구 담을 리스트\n",
    "b=[]  # 기업명 담을 리스트\n",
    "c=[]  # 접수예정, 마감 담을 리스트\n",
    "d=[]  # 주소 담을 리스트\n",
    "e=[]  # 연락처 담을 리스트\n",
    "f=[]  # 구인사항 담을 리스트\n",
    "g=[]  # 접수마감일자 담을 리스트\n",
    "\n",
    "\n",
    "page_num = [0]*len(texts)\n",
    "for idx in tqdm(range(len(texts))):\n",
    "    driver = webdriver.Chrome(r'C:\\Users\\USER\\Desktop\\chromedriver\\chromedriver.exe')\n",
    "    driver.get('https://www.seniorro.or.kr:4431/seniorro/main/main.do')\n",
    "    time.sleep(2)\n",
    "    \n",
    "    driver.execute_script(f\"jobSearchAct02{texts[idx]}\")\n",
    "    time.sleep(2)\n",
    "    html=driver.page_source\n",
    "    soup=BeautifulSoup(html, 'html.parser')\n",
    "    div = soup.find('div',{'id':'paging02'})\n",
    "\n",
    "    try:\n",
    "        page_num[idx] = int(re.sub(r'[^0-9]', '', div.find_all('a')[-1]['href']))\n",
    " \n",
    "    except:\n",
    "        page_num[idx] = 0\n",
    "\n",
    "    for nums in page_num:\n",
    "        for num in range(1, nums+1):\n",
    "\n",
    "            time.sleep(2)\n",
    "            driver.execute_script(f\"javascript:jobList({str(num)},'')\")\n",
    "            # 해당 페이지 주소들 뽑기\n",
    "            ul = soup.find('ul',{'id':'rsList02'})\n",
    "\n",
    "            for i in ul.find_all('a'):\n",
    "                url = i['href']\n",
    "\n",
    "                # 원하는 자료 추출\n",
    "                driver.execute_script(url)\n",
    "                time.sleep(2)\n",
    "\n",
    "                html=driver.page_source\n",
    "                soup=BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "                ul = soup.find('div',{'id':'detailDiv'})\n",
    "                \n",
    "                try:    \n",
    "                    a.append(' '.join(texts[idx]))  # 지역 및 시군구\n",
    "                    b.append(ul.find('span',{'id':'dJobAnnounNm'}).text)  # 기업명\n",
    "                    c.append(ul.find('span',{'id':'dDeadLine'}).text)  # 접수예정, 마감\n",
    "                    d.append(ul.find('strong',{'id':'dAddr'}).text)  # 주소\n",
    "                    e.append(ul.find('strong',{'id':'dTelNo'}).text)  # 연락처\n",
    "                    f.append(ul.find('dd',{'id':'dDetCnts'}).text)   # 구인사항\n",
    "                    g.append(ul.find('dd',{'id':'dToAcptDd'}).text)  # 접수마감일자\n",
    "                    \n",
    "                except:\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'a':a, 'b':b, 'c':c, 'd':d, 'e':e, 'f':f, 'g':g})\n",
    "df.to_csv('광주1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('대전광역시', '대덕구'), ('대전광역시', '동구'), ('대전광역시', '서구'), ('대전광역시', '유성구'), ('대전광역시', '중구'), ('대전광역시', '직속')]\n"
     ]
    }
   ],
   "source": [
    "# print(text.split('\\n'))\n",
    "\n",
    "text = ['대전광역시 대덕구', '대전광역시 동구', '대전광역시 서구', '대전광역시 유성구', '대전광역시 중구', '대전광역시 직속']\n",
    "        \n",
    "\n",
    "texts=[]\n",
    "for txt in text:\n",
    "    a = []\n",
    "    a.append(txt.split()[0])\n",
    "    a.append(' '.join(txt.split()[1:]))\n",
    "\n",
    "    texts.append(tuple(a))\n",
    "\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_23524\\2393121606.py:19: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(r'C:\\Users\\USER\\Desktop\\chromedriver\\chromedriver.exe')\n",
      "100%|██████████| 6/6 [1:44:35<00:00, 1045.91s/it]\n"
     ]
    }
   ],
   "source": [
    "# 페이지 수 뽑기\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import time\n",
    "\n",
    "a=[]  # 지역 및 시군구 담을 리스트\n",
    "b=[]  # 기업명 담을 리스트\n",
    "c=[]  # 접수예정, 마감 담을 리스트\n",
    "d=[]  # 주소 담을 리스트\n",
    "e=[]  # 연락처 담을 리스트\n",
    "f=[]  # 구인사항 담을 리스트\n",
    "g=[]  # 접수마감일자 담을 리스트\n",
    "\n",
    "\n",
    "page_num = [0]*len(texts)\n",
    "for idx in tqdm(range(len(texts))):\n",
    "    driver = webdriver.Chrome(r'C:\\Users\\USER\\Desktop\\chromedriver\\chromedriver.exe')\n",
    "    driver.get('https://www.seniorro.or.kr:4431/seniorro/main/main.do')\n",
    "    time.sleep(2)\n",
    "    \n",
    "    driver.execute_script(f\"jobSearchAct02{texts[idx]}\")\n",
    "    time.sleep(2)\n",
    "    html=driver.page_source\n",
    "    soup=BeautifulSoup(html, 'html.parser')\n",
    "    div = soup.find('div',{'id':'paging02'})\n",
    "\n",
    "    try:\n",
    "        page_num[idx] = int(re.sub(r'[^0-9]', '', div.find_all('a')[-1]['href']))\n",
    " \n",
    "    except:\n",
    "        page_num[idx] = 0\n",
    "\n",
    "    for nums in page_num:\n",
    "        for num in range(1, nums+1):\n",
    "\n",
    "            time.sleep(2)\n",
    "            driver.execute_script(f\"javascript:jobList({str(num)},'')\")\n",
    "            # 해당 페이지 주소들 뽑기\n",
    "            ul = soup.find('ul',{'id':'rsList02'})\n",
    "\n",
    "            for i in ul.find_all('a'):\n",
    "                url = i['href']\n",
    "\n",
    "                # 원하는 자료 추출\n",
    "                driver.execute_script(url)\n",
    "                time.sleep(2)\n",
    "\n",
    "                html=driver.page_source\n",
    "                soup=BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "                ul = soup.find('div',{'id':'detailDiv'})\n",
    "                \n",
    "                try:    \n",
    "                    a.append(' '.join(texts[idx]))  # 지역 및 시군구\n",
    "                    b.append(ul.find('span',{'id':'dJobAnnounNm'}).text)  # 기업명\n",
    "                    c.append(ul.find('span',{'id':'dDeadLine'}).text)  # 접수예정, 마감\n",
    "                    d.append(ul.find('strong',{'id':'dAddr'}).text)  # 주소\n",
    "                    e.append(ul.find('strong',{'id':'dTelNo'}).text)  # 연락처\n",
    "                    f.append(ul.find('dd',{'id':'dDetCnts'}).text)   # 구인사항\n",
    "                    g.append(ul.find('dd',{'id':'dToAcptDd'}).text)  # 접수마감일자\n",
    "                    \n",
    "                except:\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'a':a, 'b':b, 'c':c, 'd':d, 'e':e, 'f':f, 'g':g})\n",
    "df.to_csv('대전1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
